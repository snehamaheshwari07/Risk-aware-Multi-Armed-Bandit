{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate a random name of stock\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate random cost at 1st trial of stock\n",
    "def cost_generator(cost_low, cost_up):\n",
    "    return random.uniform(cost_low,cost_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data \n",
    "dataset=pd.read_csv(r'C:\\Users\\Sneha\\Desktop\\dataa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of assets\n",
    "no_of_assets=100\n",
    "#appending rows to dataset\n",
    "k=dataset\n",
    "for j in range(0,no_of_assets):\n",
    "    k=k.append({'Name':id_generator(),'Cost_1':cost_generator(5,15),'H1':cost_generator(0,1)},ignore_index=True)\n",
    "\n",
    "dataset=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns\n",
    "column=[]\n",
    "for j in range(0,2019):\n",
    "    x= np.random.uniform(low=0, high=2*dataset.loc[:,'H1'], size=no_of_assets)\n",
    "    column.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the headers for historical data rewards\n",
    "h=[]\n",
    "for j in range(2,21):\n",
    "    h.append('H'+str(j))\n",
    "#number of R_{i,t} trials\n",
    "no_of_trials=2000\n",
    "#naming the headers for current data rewards\n",
    "r=[]\n",
    "for j in range(1,no_of_trials+1):\n",
    "    r.append('R'+str(j))\n",
    "#appending columns \n",
    "for j in range (0,19):\n",
    "    dataset[h[j]]=column[j]\n",
    "for j in range(19,no_of_trials+19):\n",
    "    dataset[r[j-19]]=column[j]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "#historical return vectors \n",
    "historical_returns=[]\n",
    "for i in range(0,no_of_assets):\n",
    "    ro=dataset.iloc[i]\n",
    "    \n",
    "    row=ro[2:22]#here in 1:5 1 is included and 5 is not included \n",
    "    k=[log(y) for y in row]\n",
    "    historical_returns.append(k)\n",
    "\n",
    "#historical_returns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=[]\n",
    "edge_length=[]\n",
    "for i in range(0,no_of_assets):\n",
    "    delta.append([])\n",
    "    for j in range(0,no_of_assets):\n",
    "        p=[]#h_{i,t}*h_{j,t}\n",
    "        for t in range(0,20):\n",
    "            p.append(historical_returns[i][t]*historical_returns[j][t])\n",
    "        q=[]#h_{i,t}\n",
    "        for t in range(0,20):\n",
    "            q.append(historical_returns[i][t])\n",
    "        r=[]#h_{j,t}\n",
    "        for t in range(0,20):\n",
    "            r.append(historical_returns[j][t])\n",
    "        s=[]#h_{i,t}^2\n",
    "        for t in range(0,20):\n",
    "            s.append(historical_returns[i][t]*historical_returns[i][t])\n",
    "        m=[]#h_{j,t}^2\n",
    "        for t in range(0,20):\n",
    "            m.append(historical_returns[j][t]*historical_returns[j][t])\n",
    "\n",
    "        delta[i].append(((no_of_assets*sum(p))-(sum(q)*sum(r)))/np.sqrt(((no_of_assets*sum(s))-(sum(q)*sum(q)))*((no_of_assets*sum(m))-(sum(r)*sum(r)))))\n",
    "        \n",
    "for i in range(0,no_of_assets):\n",
    "    edge_length.append([])\n",
    "    for j in range(0,no_of_assets):\n",
    "        y=np.sqrt(2*(1-delta[i][j]))\n",
    "        edge_length[i].append(y)\n",
    "#edge_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge_length[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge \tWeight\n",
      "21 - 1 \t 0.5790260411796603\n",
      "11 - 2 \t 0.6009080186561269\n",
      "72 - 3 \t 0.7275018707413908\n",
      "3 - 4 \t 0.7346291543173865\n",
      "59 - 5 \t 0.7000073724119175\n",
      "69 - 6 \t 0.6200671087686137\n",
      "61 - 7 \t 0.4520606564291785\n",
      "84 - 8 \t 0.8886294174221726\n",
      "52 - 9 \t 0.505095561556886\n",
      "30 - 10 \t 0.8622882375260511\n",
      "32 - 11 \t 0.5868866366741428\n",
      "57 - 12 \t 0.7063026984711487\n",
      "60 - 13 \t 0.7935691135615386\n",
      "85 - 14 \t 0.773851481887792\n",
      "78 - 15 \t 0.7252568207347521\n",
      "69 - 16 \t 0.5384398932202783\n",
      "38 - 17 \t 0.5153695829490792\n",
      "96 - 18 \t 0.8120818010802614\n",
      "24 - 19 \t 0.6478203829877678\n",
      "61 - 20 \t 0.48508956214935217\n",
      "61 - 21 \t 0.46860103062046465\n",
      "61 - 22 \t 0.7339166825731708\n",
      "20 - 23 \t 0.5359347292561081\n",
      "78 - 24 \t 0.6571196568232691\n",
      "72 - 25 \t 0.670329063511415\n",
      "52 - 26 \t 0.5388101880592419\n",
      "60 - 27 \t 0.8165922131816711\n",
      "96 - 28 \t 0.8248126608723961\n",
      "21 - 29 \t 0.7714297046574295\n",
      "98 - 30 \t 0.8924984256623857\n",
      "54 - 31 \t 0.8756883765136452\n",
      "88 - 32 \t 0.3544022796087446\n",
      "69 - 33 \t 0.487842018046504\n",
      "23 - 34 \t 0.7778123148962172\n",
      "96 - 35 \t 0.7186782875575652\n",
      "65 - 36 \t 0.626107439342793\n",
      "16 - 37 \t 0.9311642792771994\n",
      "93 - 38 \t 0.5451679675058736\n",
      "88 - 39 \t 0.26418910654109057\n",
      "74 - 40 \t 0.7547280145866251\n",
      "51 - 41 \t 0.39188780449617877\n",
      "36 - 42 \t 0.7235584486789064\n",
      "15 - 43 \t 0.7625061583520437\n",
      "78 - 44 \t 0.336728687044242\n",
      "28 - 45 \t 0.7718390509980991\n",
      "95 - 46 \t 0.37913215683259777\n",
      "43 - 47 \t 1.0095048919697365\n",
      "95 - 48 \t 0.5801176166485807\n",
      "7 - 49 \t 0.6772963227556864\n",
      "83 - 50 \t 0.699757986208997\n",
      "57 - 51 \t 0.5762186339082686\n",
      "88 - 52 \t 0.4491068878974756\n",
      "52 - 53 \t 0.746713091547557\n",
      "38 - 54 \t 0.6875609748853183\n",
      "94 - 55 \t 0.618000694270561\n",
      "11 - 56 \t 0.6689782516027698\n",
      "60 - 57 \t 0.7254604885756251\n",
      "84 - 58 \t 0.8146050130577072\n",
      "99 - 59 \t 0.6942423839961054\n",
      "0 - 60 \t 0.7652780006079346\n",
      "39 - 61 \t 0.2913887933048299\n",
      "46 - 62 \t 0.4249475506970275\n",
      "44 - 63 \t 0.6472932972649879\n",
      "39 - 64 \t 0.5406458648670246\n",
      "41 - 65 \t 0.6300338501647651\n",
      "42 - 66 \t 0.8508937217104192\n",
      "95 - 67 \t 0.8462215423377586\n",
      "64 - 68 \t 0.6503878606719585\n",
      "32 - 69 \t 0.398315534648183\n",
      "89 - 70 \t 0.3737723822871604\n",
      "72 - 71 \t 0.7465688297195427\n",
      "78 - 72 \t 0.3650690009137243\n",
      "89 - 73 \t 1.0506759396626293\n",
      "52 - 74 \t 0.6385970646213235\n",
      "71 - 75 \t 0.8705272743629557\n",
      "56 - 76 \t 0.7099294267661569\n",
      "6 - 77 \t 0.5860997154056872\n",
      "88 - 78 \t 0.33924373926325424\n",
      "90 - 79 \t 0.7093563912402472\n",
      "82 - 80 \t 0.7814797882229445\n",
      "17 - 81 \t 0.714626379983945\n",
      "24 - 82 \t 0.6624396584532746\n",
      "20 - 83 \t 0.5085038796992246\n",
      "97 - 84 \t 0.6017125294820423\n",
      "67 - 85 \t 0.7805336446206101\n",
      "62 - 86 \t 0.6109648561060196\n",
      "63 - 87 \t 0.8967171110632802\n",
      "51 - 88 \t 0.3182854009302319\n",
      "88 - 89 \t 0.503980530276166\n",
      "23 - 90 \t 0.7747988951210201\n",
      "46 - 91 \t 0.6717407980194852\n",
      "91 - 92 \t 0.6358925446179812\n",
      "78 - 93 \t 0.44131658854032707\n",
      "33 - 94 \t 0.6098539596537322\n",
      "61 - 95 \t 0.3467250049624639\n",
      "95 - 96 \t 0.4549260532124505\n",
      "86 - 97 \t 0.6502406895408975\n",
      "16 - 98 \t 0.7869339225408495\n",
      "95 - 99 \t 0.42676763385719374\n",
      "[0, 22, 12, 73, 4, 60, 70, 62, 85, 53, 31, 33, 58, 61, 86, 79, 70, 39, 97, 25, 62, 62, 62, 21, 79, 73, 53, 61, 97, 22, 99, 55, 89, 70, 24, 97, 66, 17, 94, 89, 75, 52, 37, 16, 79, 29, 96, 44, 96, 8, 84, 58, 89, 53, 39, 95, 12, 61, 85, 100, 1, 40, 47, 45, 40, 42, 43, 96, 65, 33, 90, 73, 79, 90, 53, 72, 57, 7, 89, 91, 83, 18, 25, 21, 98, 68, 63, 64, 52, 89, 24, 47, 92, 79, 34, 62, 96, 87, 17, 96]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 19,\n",
       " 20,\n",
       " 23,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 35,\n",
       " 36,\n",
       " 38,\n",
       " 41,\n",
       " 46,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 54,\n",
       " 56,\n",
       " 59,\n",
       " 67,\n",
       " 69,\n",
       " 71,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 88,\n",
       " 93]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prim's algo to calculate adjecency matrix for minimum spanning tree\n",
    "import sys # Library for INT_MAX \n",
    "from itertools import chain\n",
    "from operator import sub\n",
    "imap=map\n",
    "  \n",
    "class Graph(): \n",
    "  \n",
    "    def __init__(self, vertices): \n",
    "        self.V = vertices \n",
    "        self.graph = [[0 for column in range(vertices)]  \n",
    "                    for row in range(vertices)] \n",
    "  \n",
    "    # A utility function to print the constructed MST stored in parent[] \n",
    "    def printMST(self, parent): \n",
    "        print(\"Edge \\tWeight\")\n",
    "        for i in range(1,self.V):\n",
    "            print(parent[i],\"-\",i,\"\\t\",self.graph[i][ parent[i] ])\n",
    "            \n",
    "\n",
    "    \n",
    "    def missing_numbers(self,parent):\n",
    "        parent.sort()\n",
    "        original_list = [x for x in range(parent[0], no_of_assets + 1)]\n",
    "        parent = set(parent)\n",
    "        return (list(parent ^ set(original_list)))\n",
    "    \n",
    "  \n",
    "    # A utility function to find the vertex with  \n",
    "    # minimum distance value, from the set of vertices  \n",
    "    # not yet included in shortest path tree \n",
    "    def minKey(self, key, mstSet): \n",
    "  \n",
    "        # Initilaize min value \n",
    "        min = sys.maxsize \n",
    "  \n",
    "        for v in range(self.V): \n",
    "            if key[v] < min and mstSet[v] == False: \n",
    "                min = key[v] \n",
    "                min_index = v \n",
    "  \n",
    "        return min_index \n",
    "  \n",
    "    # Function to construct and print MST for a graph  \n",
    "    # represented using adjacency matrix representation \n",
    "    def primMST(self): \n",
    "  \n",
    "        #Key values used to pick minimum weight edge in cut \n",
    "        key = [sys.maxsize] * self.V \n",
    "        parent = [None] * self.V # Array to store constructed MST \n",
    "        # Make key 0 so that this vertex is picked as first vertex \n",
    "        key[0] = 0 \n",
    "        mstSet = [False] * self.V \n",
    "  \n",
    "        parent[0] = -1 # First node is always the root of \n",
    "  \n",
    "        for cout in range(self.V): \n",
    "  \n",
    "            # Pick the minimum distance vertex from  \n",
    "            # the set of vertices not yet processed.  \n",
    "            # u is always equal to src in first iteration \n",
    "            u = self.minKey(key, mstSet) \n",
    "  \n",
    "            # Put the minimum distance vertex in  \n",
    "            # the shortest path tree \n",
    "            mstSet[u] = True\n",
    "  \n",
    "            # Update dist value of the adjacent vertices  \n",
    "            # of the picked vertex only if the current  \n",
    "            # distance is greater than new distance and \n",
    "            # the vertex in not in the shotest path tree \n",
    "            for v in range(self.V): \n",
    "                # graph[u][v] is non zero only for adjacent vertices of m \n",
    "                # mstSet[v] is false for vertices not yet included in MST \n",
    "                # Update the key only if graph[u][v] is smaller than key[v] \n",
    "                if self.graph[u][v] > 0 and mstSet[v] == False and key[v] > self.graph[u][v]: \n",
    "                        key[v] = self.graph[u][v] \n",
    "                        parent[v] = u \n",
    "  \n",
    "        self.printMST(parent)\n",
    "        new_list = [x+1 for x in parent]\n",
    "        print(new_list)\n",
    "        return(self.missing_numbers(new_list))\n",
    "        \n",
    "\n",
    "g = Graph(100) \n",
    "n = 100\n",
    "matrix = np.zeros((n,100)) # Pre-allocate matrix\n",
    "for i in range(0,n):\n",
    "    matrix[i,:] = edge_length[i]\n",
    "g.graph = matrix\n",
    "  \n",
    "k=g.primMST(); \n",
    "k\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dataset.loc[k,:]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate reward\n",
    "historical_reward=[]\n",
    "present_reward=[]\n",
    "\n",
    "for t in range(1,21):\n",
    "   # historical_reward.append([])\n",
    "    #m=[]\n",
    "    #for i in range(0,len(k)):\n",
    "    historical_reward.append((4/3)*(1+((np.pi)*(np.arctan(np.log(df.loc[:,'H'+str(t)])))))**2-(4/3))\n",
    "for t in range(1,no_of_trials+1):\n",
    "    present_reward.append((4/3)*(1+((np.pi)*(np.arctan(np.log(df.loc[:,'R'+str(t)])))))**2-(4/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical reward vector has different indexes \n",
    "#hence to take average columnwise, we have to construsct another variable 'p'\n",
    "p=[]\n",
    "for i in range(0,20):\n",
    "    p.append(historical_reward[i][k[1]])\n",
    "#p\n",
    "#sum(p)/len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get estimated reward vector at trial t\n",
    "def get_mean(t):\n",
    "    asset, trial = no_of_assets, no_of_trials;\n",
    "    r_hat = [] #\\hat{r_{i,t}}\n",
    "    for i in range(0,len(k)):\n",
    "        if(t==1):\n",
    "            p=[]\n",
    "            for j in range(0,20):\n",
    "                p.append(historical_reward[j][k[i]])\n",
    "            r_hat.append(sum(p)/len(p))\n",
    "            #r_hat.append(df.loc[i,\"H1\":\"H20\"].mean()) \n",
    "        else:\n",
    "            q=[]\n",
    "            for j in range(0,20):\n",
    "                q.append(historical_reward[j][k[i]])\n",
    "            for j in range(0,no_of_trials):\n",
    "                q.append(present_reward[j][k[i]])\n",
    "            r_hat.append(sum(q)/len(q))\n",
    "            #r_hat.append(df.loc[i,\"H1\":\"R\"+str(t-1)].mean())\n",
    "    return r_hat\n",
    "#get_mean(1)\n",
    "#get_mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO module docstring\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseOptimizer:\n",
    "    def __init__(self, n_assets, weight_bounds=(0, 1)):\n",
    "        \"\"\"\n",
    "        :param weight_bounds: minimum and maximum weight of an asset, defaults to (0, 1).\n",
    "                              Must be changed to (-1, 1) for portfolios with shorting.\n",
    "        :type weight_bounds: tuple, optional\n",
    "        \"\"\"\n",
    "        self.n_assets = n_assets\n",
    "        self.bounds = self._make_valid_bounds(weight_bounds)\n",
    "        # Optimisation parameters\n",
    "        self.initial_guess = np.array([1 / self.n_assets] * self.n_assets)\n",
    "        self.constraints = [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1}]\n",
    "        # Outputs\n",
    "        self.weights = None\n",
    "\n",
    "    def _make_valid_bounds(self, test_bounds):\n",
    "        \"\"\"\n",
    "        Private method: process input bounds into a form acceptable by scipy.optimize,\n",
    "        and check the validity of said bounds.\n",
    "        :param test_bounds: minimum and maximum weight of an asset\n",
    "        :type test_bounds: tuple\n",
    "        :raises ValueError: if ``test_bounds`` is not a tuple of length two.\n",
    "        :raises ValueError: if the lower bound is too high\n",
    "        :return: a tuple of bounds, e.g ((0, 1), (0, 1), (0, 1) ...)\n",
    "        :rtype: tuple of tuples\n",
    "        \"\"\"\n",
    "        if len(test_bounds) != 2 or not isinstance(test_bounds, tuple):\n",
    "            raise ValueError(\n",
    "                \"test_bounds must be a tuple of (lower bound, upper bound)\"\n",
    "            )\n",
    "        if test_bounds[0] is not None:\n",
    "            if test_bounds[0] * self.n_assets > 1:\n",
    "                raise ValueError(\"Lower bound is too high\")\n",
    "        return (test_bounds,) * self.n_assets\n",
    "\n",
    "    def clean_weights(self, cutoff=1e-4, rounding=5):\n",
    "        \"\"\"\n",
    "        Helper method to clean the raw weights, setting any weights whose absolute\n",
    "        values are below the cutoff to zero, and rounding the rest.\n",
    "        :param cutoff: the lower bound, defaults to 1e-4\n",
    "        :type cutoff: float, optional\n",
    "        :param rounding: number of decimal places to round the weights, defaults to 5.\n",
    "                         Set to None if rounding is not desired.\n",
    "        :type rounding: int, optional\n",
    "        :return: asset weights\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        if not isinstance(rounding, int) or rounding < 1:\n",
    "            raise ValueError(\"rounding must be a positive integer\")\n",
    "        clean_weights = self.weights.copy()\n",
    "        clean_weights[np.abs(clean_weights) < cutoff] = 0\n",
    "        if rounding is not None:\n",
    "            clean_weights = np.round(clean_weights, rounding)\n",
    "        return dict(zip(self.tickers, clean_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The ``objective_functions`` module provides optimisation objectives, including the actual\n",
    "objective functions called by the ``EfficientFrontier`` object's optimisation methods.\n",
    "These methods are primarily designed for internal use during optimisation (via\n",
    "scipy.optimize), and each requires a certain signature (which is why they have not been\n",
    "factored into a class). For obvious reasons, any objective function must accept ``weights``\n",
    "as an argument, and must also have at least one of ``expected_returns`` or ``cov_matrix``.\n",
    "Because scipy.optimize only minimises, any objectives that we want to maximise must be\n",
    "made negative.\n",
    "Currently implemented:\n",
    "- negative mean return\n",
    "- (regularised) negative Sharpe ratio\n",
    "- (regularised) volatility\n",
    "- CVaR (expected shortfall)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def negative_mean_return(weights, expected_returns):\n",
    "    \"\"\"\n",
    "    Calculate the negative mean return of a portfolio\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param expected_returns: expected return of each asset\n",
    "    :type expected_returns: pd.Series\n",
    "    :return: negative mean return\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return -weights.dot(expected_returns)\n",
    "\n",
    "\n",
    "def negative_sharpe(\n",
    "    weights, expected_returns, cov_matrix, gamma=0, risk_free_rate=0.02\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the negative Sharpe ratio of a portfolio\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param expected_returns: expected return of each asset\n",
    "    :type expected_returns: pd.Series\n",
    "    :param cov_matrix: the covariance matrix of asset returns\n",
    "    :type cov_matrix: pd.DataFrame\n",
    "    :param gamma: L2 regularisation parameter, defaults to 0. Increase if you want more\n",
    "                    non-negligible weights\n",
    "    :type gamma: float, optional\n",
    "    :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02\n",
    "    :type risk_free_rate: float, optional\n",
    "    :return: negative Sharpe ratio\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    mu = weights.dot(expected_returns)\n",
    "    sigma = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights.T)))\n",
    "    L2_reg = gamma * (weights ** 2).sum()\n",
    "    return -(mu - risk_free_rate) / sigma + L2_reg\n",
    "\n",
    "\n",
    "def volatility(weights, cov_matrix, gamma=0):\n",
    "    \"\"\"\n",
    "    Calculate the volatility of a portfolio. This is actually a misnomer because\n",
    "    the function returns variance, which is technically the correct objective\n",
    "    function when minimising volatility.\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param cov_matrix: the covariance matrix of asset returns\n",
    "    :type cov_matrix: pd.DataFrame\n",
    "    :param gamma: L2 regularisation parameter, defaults to 0. Increase if you want more\n",
    "                  non-negligible weights\n",
    "    :type gamma: float, optional\n",
    "    :return: portfolio variance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    L2_reg = gamma * (weights ** 2).sum()\n",
    "    portfolio_volatility = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    return portfolio_volatility + L2_reg\n",
    "\n",
    "\n",
    "def negative_cvar(weights, returns, s=10000, beta=0.95, random_state=None):\n",
    "    \"\"\"\n",
    "    Calculate the negative CVaR. Though we want the \"min CVaR portfolio\", we\n",
    "    actually need to maximise the expected return of the worst q% cases, thus\n",
    "    we need this value to be negative.\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param returns: asset returns\n",
    "    :type returns: pd.DataFrame or np.ndarray\n",
    "    :param s: number of bootstrap draws, defaults to 10000\n",
    "    :type s: int, optional\n",
    "    :param beta: \"significance level\" (i. 1 - q), defaults to 0.95\n",
    "    :type beta: float, optional\n",
    "    :param random_state: seed for random sampling, defaults to None\n",
    "    :type random_state: int, optional\n",
    "    :return: negative CVaR\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    np.random.seed(seed=random_state)\n",
    "    # Calcualte the returns given the weights\n",
    "    weights_new = weights.reshape((df.shape[0], 1))\n",
    "    portfolio_returns = (weights_new* returns).sum(axis=0)\n",
    "    # Sample from the historical distribution\n",
    "    dist = scipy.stats.gaussian_kde(portfolio_returns)\n",
    "    sample = dist.resample(s)\n",
    "    # Calculate the value at risk\n",
    "    var = portfolio_returns.quantile(1 - beta)\n",
    "    # Mean of all losses worse than the value at risk\n",
    "    return -sample[sample < var].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The ``value_at_risk`` module allows for optimisation with a (conditional)\n",
    "value-at-risk (CVaR) objective, which requires Monte Carlo simulation.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "#from .base_optimizer import BaseOptimizer\n",
    "#from . import objective_functions\n",
    "import noisyopt\n",
    "\n",
    "\n",
    "class CVAROpt(BaseOptimizer):\n",
    "\n",
    "    \"\"\"\n",
    "    A CVAROpt object (inheriting from BaseOptimizer) provides a method for\n",
    "    optimising the CVaR (a.k.a expected shortfall) of a portfolio.\n",
    "    Instance variables:\n",
    "    - Inputs\n",
    "        - ``tickers``\n",
    "        - ``returns``\n",
    "        - ``bounds``\n",
    "    - Optimisation parameters:\n",
    "        - ``s``: the number of Monte Carlo simulations\n",
    "        - ``beta``: the critical value\n",
    "    - Output: ``weights``\n",
    "    Public methods:\n",
    "    - ``min_cvar()``\n",
    "    - ``normalize_weights()``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, returns, weight_bounds=(0, 1)):\n",
    "        \"\"\"\n",
    "        :param returns: asset historical returns\n",
    "        :type returns: pd.DataFrame\n",
    "        :param weight_bounds: minimum and maximum weight of an asset, defaults to (0, 1).\n",
    "                              Must be changed to (-1, 1) for portfolios with shorting.\n",
    "                              For CVaR opt, this is not a hard boundary.\n",
    "        :type weight_bounds: tuple, optional\n",
    "        :raises TypeError: if ``returns`` is not a dataframe\n",
    "        \"\"\"\n",
    "        if not isinstance(returns, pd.DataFrame):\n",
    "            raise TypeError(\"returns are not a dataframe\")\n",
    "        self.returns = returns\n",
    "        self.tickers = returns.index\n",
    "        super().__init__(returns.shape[0], weight_bounds)  # bounds\n",
    "\n",
    "    def min_cvar(self, s=10000, beta=0.95, random_state=None):\n",
    "        \"\"\"\n",
    "        Find the portfolio weights that minimises the CVaR, via\n",
    "        Monte Carlo sampling from the return distribution.\n",
    "        :param s: number of bootstrap draws, defaults to 10000\n",
    "        :type s: int, optional\n",
    "        :param beta: \"significance level\" (i. 1 - q), defaults to 0.95\n",
    "        :type beta: float, optional\n",
    "        :param random_state: seed for random sampling, defaults to None\n",
    "        :type random_state: int, optional\n",
    "        :return: asset weights for the Sharpe-maximising portfolio\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        args = (self.returns, s, beta, random_state)\n",
    "        result = noisyopt.minimizeSPSA(\n",
    "            negative_cvar,\n",
    "            args=args,\n",
    "            bounds=self.bounds,\n",
    "            x0=self.initial_guess,\n",
    "            niter=1000,\n",
    "            paired=False,\n",
    "        )\n",
    "        self.weights = self.normalize_weights(result[\"x\"])\n",
    "        return dict(zip(self.tickers, self.weights))\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_weights(raw_weights):\n",
    "        \"\"\"\n",
    "        Make all weights sum to 1\n",
    "        :param raw_weights: input weights which do not sum to 1\n",
    "        :type raw_weights: np.array, pd.Series\n",
    "        :return: normalized weights\n",
    "        :rtype: np.array, pd.Series\n",
    "        \"\"\"\n",
    "        return raw_weights / raw_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8397333037509118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8611616224662961"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cvar if I weight all assets equally \n",
    "ddf = df.loc[:,\"H1\":]\n",
    "returns = ddf.pct_change(axis='columns').dropna(how=\"all\")\n",
    "w = np.array([1 / df.shape[0]] * df.shape[0])\n",
    "w_new = w.reshape((df.shape[0], 1))\n",
    "cvar0 = negative_cvar(w_new, returns, s=5000, random_state=0)\n",
    "#assert cvar0 > 0\n",
    "cvar1 = negative_cvar(w_new, returns, s=5000, beta=0.98, random_state=0)\n",
    "#assert cvar1 > 0\n",
    "\n",
    "#Nondeterministic\n",
    "cvar2 = negative_cvar(w_new, returns, s=5000, random_state=1)\n",
    "assert not cvar0 == cvar2\n",
    "print(cvar0)\n",
    "cvar2\n",
    "returns\n",
    "w_new\n",
    "cvar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7452261802202003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min cvar \n",
    "vr = CVAROpt(returns)\n",
    "w1 = vr.min_cvar(s=5000, random_state=0)\n",
    "assert isinstance(w1, dict)\n",
    "assert set(w1.keys()) == set(ddf.index)\n",
    "assert set(w1.keys()) == set(vr.tickers)\n",
    "np.testing.assert_almost_equal(vr.weights.sum(), 1)\n",
    "\n",
    "w1\n",
    "w1=np.array(list(dict.values(w1)))\n",
    "w1\n",
    "w1_new = w1.reshape((df.shape[0], 1))\n",
    "cvar_min = negative_cvar(w1_new, returns, s=5000, random_state=0)\n",
    "cvar_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LPSolution(object):\n",
    "    def __init__(self):\n",
    "        self.iterations = None\n",
    "        self.tolerance = None\n",
    "        self.intermediates = []\n",
    "        self.solution = None\n",
    "        self.solution_string = None\n",
    "\n",
    "    def __str__(self):\n",
    "        self.solution_string = 'Solution: ' + str(self.solution)\n",
    "        self.solution_string += '\\n\\tTolerance: ' + str(self.tolerance)\n",
    "        self.solution_string += '\\n\\tIterations: ' + str(self.iterations)\n",
    "        return self.solution_string\n",
    "\n",
    "\n",
    "class LinearProgram(object):\n",
    "    \"\"\"A class that implements Karmarkar's Algorithm for the solution of\n",
    "    Linear Programs in standard form.\"\"\"\n",
    "    def __init__(self, A, b, c):\n",
    "        \"\"\"Constructs an n-variable m-constraint Linear Program.\n",
    "\n",
    "        A -- An n x m numpy matrix of constraint coefficients\n",
    "        b -- A 1 x m numpy row vector of constraint RHS values\n",
    "        c -- A 1 x n numpy row vector of objective function coefficients\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.n, self.m = self.A.shape\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.solution = None\n",
    "\n",
    "    def karmarkar(self, start_point):\n",
    "        \"\"\"Runs one iteration of Karmarkar's Algorithm.\n",
    "\n",
    "        start_point -- A 1 x n numpy row vector of decision variable values\n",
    "        \"\"\"\n",
    "        D = np.diagflat(start_point)\n",
    "        c_tilde = np.matmul(self.c, D)\n",
    "        A_tilde = np.matmul(self.A, D)\n",
    "        A_tildeT = A_tilde.transpose()\n",
    "        AAT_inverse = np.linalg.inv(np.matmul(A_tilde, A_tildeT))\n",
    "        # matrix multiplication is associative\n",
    "        P = np.identity(self.m) - np.matmul(np.matmul(A_tildeT, AAT_inverse), A_tilde)\n",
    "        cp_tilde = np.matmul(c_tilde, P)\n",
    "        k = -0.5 / np.amin(cp_tilde)\n",
    "        x_tilde_new = np.ones((1, self.m), order='F') + k * cp_tilde\n",
    "        return np.matmul(x_tilde_new, D)\n",
    "\n",
    "    def solve(self, start_point, tolerance=1e-5, max_iterations=50, verbose=False):\n",
    "        \"\"\"Uses Karmarkar's Algorithm to solve a Linear Program.\n",
    "\n",
    "        start_point     -- A starting point for Karmarkar's Algorithm. Must be a row vector.\n",
    "        tolerance       -- The stopping tolerance of Karmarkar's Algorithm.\n",
    "        max_iterations  -- The maximum number of iterations to run Karmarkar's Algorithm.\n",
    "        verbose         -- List all intermediate values.\n",
    "        \"\"\"\n",
    "        x = start_point\n",
    "        solution = LPSolution()\n",
    "        for i in range(max_iterations):\n",
    "            x_new = self.karmarkar(x)\n",
    "            if verbose:\n",
    "                print(x_new)\n",
    "\n",
    "            dist = np.linalg.norm(x - x_new)\n",
    "            x = x_new\n",
    "            solution.intermediates.append(x)\n",
    "            if dist < tolerance:\n",
    "                break\n",
    "\n",
    "        solution.solution = x\n",
    "        solution.iterations = i\n",
    "        solution.tolerance = dist\n",
    "        self.solution = solution\n",
    "\n",
    "        return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [[  2.97874012e-06   7.99999553e+00   1.48937006e-06]]\n",
      "\tTolerance: 5.57390111055e-06\n",
      "\tIterations: 21\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import numpy as np\n",
    "#from linear_program import LinearProgram, LPSolution\n",
    "\n",
    "\n",
    "def generate_tikz_plot(solution):\n",
    "    \"\"\"Generates a 3D Tikz LaTeX coordinate strings for the intermediate solutions.\"\"\"\n",
    "    for i, soln in enumerate(solution.intermediates):\n",
    "        coordinate = r'\\coordinate (xnew{}) at '.format(i)\n",
    "        coordinate += r'({}, {}, {});'.format(*[coord for coord in soln.flat])\n",
    "        print(coordinate)\n",
    "\n",
    "    draw = r'\\draw[red] (x) node[circle, fill, inner sep=1pt] '\n",
    "    for i in range(len(solution.intermediates)):\n",
    "        draw += r'-- (xnew{}) node[circle, fill, inner sep=1pt] '.format(i)\n",
    "    draw += r';'\n",
    "    print(draw)\n",
    "\n",
    "\n",
    "def main():\n",
    "    A = np.matrix([[1, 1, 1], ])\n",
    "    b = np.array([8, ])\n",
    "    c = np.array([1, 2, 0])\n",
    "\n",
    "    LP = LinearProgram(A, b, c)\n",
    "    LP.solve(start_point=np.array([1, 1, 6]))\n",
    "    print(LP.solution)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygraphviz from git+git://github.com/pygraphviz/pygraphviz.git#egg=pygraphviz\n",
      "  Cloning git://github.com/pygraphviz/pygraphviz.git to c:\\users\\sneha\\appdata\\local\\temp\\pip-build-mtzlyp1j\\pygraphviz\n",
      "Installing collected packages: pygraphviz\n",
      "  Running setup.py install for pygraphviz\n",
      "    Complete output from command c:\\users\\sneha\\anaconda3\\python.exe -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-build-mtzlyp1j\\\\pygraphviz\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Sneha\\AppData\\Local\\Temp\\pip-xws56ir5-record\\install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    include_dirs=None\n",
      "    library_dirs=None\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.6\n",
      "    creating build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\agraph.py -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\release.py -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\version.py -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\__init__.py -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    creating build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_attributes.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_setup.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-3.6\\pygraphviz\\tests\n",
      "    running egg_info\n",
      "    creating pygraphviz.egg-info\n",
      "    writing pygraphviz.egg-info\\PKG-INFO\n",
      "    writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "    writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "    writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "    reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    c:\\users\\sneha\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:351: UserWarning: Normalizing '1.6.dev' to '1.6.dev0'\n",
      "      normalized_version,\n",
      "    warning: no files found matching '*.png' under directory 'doc'\n",
      "    warning: no files found matching '*.html' under directory 'doc'\n",
      "    warning: no files found matching '*.txt' under directory 'doc'\n",
      "    warning: no files found matching '*.css' under directory 'doc'\n",
      "    warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "    no previously-included directories found matching 'doc\\build'\n",
      "    writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "    copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-3.6\\pygraphviz\n",
      "    running build_ext\n",
      "    building 'pygraphviz._graphviz' extension\n",
      "    creating build\\temp.win-amd64-3.6\n",
      "    creating build\\temp.win-amd64-3.6\\Release\n",
      "    creating build\\temp.win-amd64-3.6\\Release\\pygraphviz\n",
      "    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ic:\\users\\sneha\\anaconda3\\include -Ic:\\users\\sneha\\anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-3.6\\Release\\pygraphviz/graphviz_wrap.obj\n",
      "    graphviz_wrap.c\n",
      "    pygraphviz/graphviz_wrap.c(2987): fatal error C1083: Cannot open include file: 'graphviz/cgraph.h': No such file or directory\n",
      "    error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2017\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.16.27023\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit status 2\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"c:\\users\\sneha\\anaconda3\\python.exe -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Sneha\\\\AppData\\\\Local\\\\Temp\\\\pip-build-mtzlyp1j\\\\pygraphviz\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Sneha\\AppData\\Local\\Temp\\pip-xws56ir5-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\Sneha\\AppData\\Local\\Temp\\pip-build-mtzlyp1j\\pygraphviz\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/pygraphviz/pygraphviz.git#egg=pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Python Script to generate complete graph\n",
    "#\n",
    "\n",
    "NUM_NODES = 20\n",
    "\n",
    "print \"Creating complete graph with \" + str(NUM_NODES) + \" nodes...\"\n",
    "\n",
    "new_network = cyAppAdapter.getCyNetworkFactory().createNetwork()\n",
    "new_network.getRow(new_network).set(\"name\", \"Complete Graph Created by Python Script\")\n",
    "cyAppAdapter.getCyNetworkManager().addNetwork(new_network);\n",
    "\n",
    "# Add nodes\n",
    "nodes = [];\n",
    "for i in range (NUM_NODES):\n",
    "    node_name = \"Node \" + str(i)\n",
    "    node = new_network.addNode()\n",
    "    new_network.getRow(node).set(\"name\", node_name)\n",
    "    nodes.append(node)\n",
    "\n",
    "# Add edges\n",
    "edge_count = 0;\n",
    "for source in nodes:\n",
    "    for target in nodes:\n",
    "        if new_network.containsEdge(source, target) is False \\\n",
    "                and new_network.containsEdge(target, source) is False \\\n",
    "                and source is not target:\n",
    "            edge = new_network.addEdge(source, target, True)\n",
    "            edge_count = edge_count + 1\n",
    "            new_network.getRow(edge).set(\"name\", \"Edge \" + str(edge_count))\n",
    "            new_network.getRow(edge).set(\"interaction\", \"interacts_with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
