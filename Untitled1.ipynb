{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = whole set \n",
    "#df = set of selected assets only\n",
    "#return = log(c_{i,t}/c_{i,t+1}\n",
    "#reward = (4/3)*(1+((np.pi)*(np.arctan(np.log(df.loc[:,'H'+str(t)])))))**2-(4/3)\n",
    "#T[i]= number of times asset i is selected for set S (started it from 20)\n",
    "#mu= algoritm confidence level belongs to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions :\n",
    "#  get_cost(t)  \n",
    "#estimated_reward\n",
    "#estimated_reward_plus\n",
    "#estimated_reward_minus\n",
    "#get_cost_for_k\n",
    "#get_start_point() it gives x_{i,1}'s for all i's\n",
    "#negative_cvar\n",
    "#et_weight_from_securities() #get weights of each asset from x_{i,t}'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate a random name of stock\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate random cost at 1st trial of stock\n",
    "def cost_generator(cost_low, cost_up):\n",
    "    return random.uniform(cost_low,cost_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data \n",
    "dataset=pd.read_csv(r'C:\\Users\\Sneha\\Desktop\\dataa.csv')\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta\n",
    "theta=5\n",
    "#Cost Bound\n",
    "Cost_Bound=100\n",
    "#number of assets\n",
    "no_of_assets=100\n",
    "#algorithm satisfy constraints with probability atleast (1-mu) \n",
    "mu= 0.1\n",
    "#number of R_{i,t} trials\n",
    "no_of_trials=2000\n",
    "\n",
    "#appending rows to dataset\n",
    "p=dataset\n",
    "for j in range(0,no_of_assets):\n",
    "    p=p.append({'Name':id_generator(),'Cost_1':cost_generator(5,15),'H1':cost_generator(0,1)},ignore_index=True)\n",
    "\n",
    "dataset=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns\n",
    "column=[]\n",
    "for j in range(0,2019):\n",
    "    x= np.random.uniform(low=0, high=2*dataset.loc[:,'H1'], size=no_of_assets)\n",
    "    column.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the headers for historical data rewards\n",
    "h=[]\n",
    "for j in range(2,21):\n",
    "    h.append('H'+str(j))\n",
    "\n",
    "#naming the headers for current data rewards\n",
    "r=[]\n",
    "for j in range(1,no_of_trials+1):\n",
    "    r.append('R'+str(j))\n",
    "#appending columns \n",
    "for j in range (0,19):\n",
    "    dataset[h[j]]=column[j]\n",
    "for j in range(19,no_of_trials+19):\n",
    "    dataset[r[j-19]]=column[j]\n",
    "\n",
    "\n",
    "#dataset\n",
    "# here columns of dataset represent (c_{i,t+1}/c_{i,t}) \n",
    "#considering trial 1 at Cost_1\n",
    "# H1 implies c_{i,2}/c_{i,1}\n",
    "#cost at trial 2 is H1*Cost_1\n",
    "#at trial 2 H2 is unknown \n",
    "#reward at trial 2 is determined using H2 \n",
    "#if H20 is considered to be the start\n",
    "#then cost at trial 1 is multiplication of columns till H20(all historical returns)\n",
    "#trial 1 begins from R1, where cost will be calculated by multiplying dataset entries till 20\n",
    "# And trial 1 estimated reward vector will be mean of reward till H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(t):\n",
    "    if (t==1):\n",
    "        y=np.multiply(dataset.loc[:,\"Cost_1\"],dataset.loc[:,\"H1\"])\n",
    "        i=2\n",
    "        while (i<=20):\n",
    "            y=np.multiply(y,dataset.loc[:,\"H\"+str(i)])\n",
    "            i=i+1\n",
    "    else:\n",
    "        y=np.multiply(dataset.loc[:,\"Cost_1\"],dataset.loc[:,\"H1\"])\n",
    "        i=2\n",
    "        while (i<=20):\n",
    "            y=np.multiply(y,dataset.loc[:,\"H\"+str(i)])\n",
    "            i=i+1\n",
    "        j=1\n",
    "        while (j<=(t-1)):\n",
    "            y=np.multiply(y,dataset.loc[:,\"R\"+str(j)])\n",
    "            j=j+1   \n",
    "            \n",
    "    return list(y)\n",
    "#get_cost(2) will return cost of assets at trial 2 by multiplying till R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing of cost vector \n",
    "#y=np.multiply(dataset.loc[:,\"Cost_1\"],dataset.loc[:,\"H1\"])\n",
    "#i=2\n",
    "#while (i<=20):\n",
    "#    y=np.multiply(y,dataset.loc[:,\"H\"+str(i)])\n",
    "#    i=i+1\n",
    "#y\n",
    "#np.multiply(y, dataset.loc[:,\"R1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing np.multiply\n",
    "#a=[1,2]\n",
    "#b=[2,3]\n",
    "#c=[3,4]\n",
    "#np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge \tWeight\n",
      "20 - 1 \t 0.3888177843919737\n",
      "33 - 2 \t 0.6999750263239773\n",
      "1 - 3 \t 0.495589611355284\n",
      "87 - 4 \t 0.2953247624478681\n",
      "99 - 5 \t 0.8638174757079964\n",
      "87 - 6 \t 0.3478557297506196\n",
      "49 - 7 \t 0.5460477457169143\n",
      "58 - 8 \t 0.24421990334964488\n",
      "62 - 9 \t 0.5155400199920608\n",
      "85 - 10 \t 0.5644134466431631\n",
      "43 - 11 \t 0.44436441861350884\n",
      "57 - 12 \t 0.7575204036335301\n",
      "38 - 13 \t 0.9199262719188115\n",
      "7 - 14 \t 0.7487858401723207\n",
      "6 - 15 \t 0.6414355703499114\n",
      "11 - 16 \t 0.8518549028995098\n",
      "54 - 17 \t 0.6805568665529365\n",
      "64 - 18 \t 0.8106676892546665\n",
      "47 - 19 \t 0.6242178857242777\n",
      "8 - 20 \t 0.22387919179675528\n",
      "85 - 21 \t 0.30096664310508764\n",
      "13 - 22 \t 0.848751263998743\n",
      "49 - 23 \t 0.6464672822463022\n",
      "43 - 24 \t 0.6011579780440213\n",
      "85 - 25 \t 0.39282906321170546\n",
      "61 - 26 \t 0.6277740743912438\n",
      "62 - 27 \t 0.7799497431281406\n",
      "35 - 28 \t 0.6226823454198733\n",
      "43 - 29 \t 0.42640466500682983\n",
      "15 - 30 \t 0.8733866829286463\n",
      "63 - 31 \t 0.8928065854624879\n",
      "66 - 32 \t 0.8440350583432048\n",
      "74 - 33 \t 0.43371559547083205\n",
      "60 - 34 \t 0.40942201250854027\n",
      "85 - 35 \t 0.4827545140302579\n",
      "21 - 36 \t 0.7298040875132111\n",
      "10 - 37 \t 0.7352080641882669\n",
      "49 - 38 \t 0.4888555031830473\n",
      "61 - 39 \t 0.6554014582756552\n",
      "87 - 40 \t 0.39098089301171024\n",
      "25 - 41 \t 0.7893053049780667\n",
      "8 - 42 \t 0.3553674521583557\n",
      "85 - 43 \t 0.3198180102117863\n",
      "3 - 44 \t 0.740483086099543\n",
      "41 - 45 \t 0.9827452532064748\n",
      "85 - 46 \t 0.3869235129201976\n",
      "34 - 47 \t 0.23354205321080737\n",
      "77 - 48 \t 0.5794808570308823\n",
      "8 - 49 \t 0.35577469105142645\n",
      "74 - 50 \t 0.5457439711865663\n",
      "12 - 51 \t 0.8165213675765144\n",
      "47 - 52 \t 0.5730934203181479\n",
      "41 - 53 \t 1.1364431371688066\n",
      "35 - 54 \t 0.6337366294730541\n",
      "1 - 55 \t 0.44542431571227\n",
      "86 - 56 \t 0.721843585720989\n",
      "46 - 57 \t 0.5735423508077864\n",
      "0 - 58 \t 0.5651035456520614\n",
      "8 - 59 \t 0.29682002144504144\n",
      "58 - 60 \t 0.29544902928799804\n",
      "20 - 61 \t 0.31620265549384025\n",
      "4 - 62 \t 0.49292276883284464\n",
      "97 - 63 \t 0.5552389586582958\n",
      "85 - 64 \t 0.3019244539308244\n",
      "56 - 65 \t 0.7828096338823536\n",
      "0 - 66 \t 0.6397551591609247\n",
      "20 - 67 \t 0.5382914710121633\n",
      "42 - 68 \t 0.6651479899538849\n",
      "81 - 69 \t 0.6342665084602165\n",
      "26 - 70 \t 0.7864163815088325\n",
      "52 - 71 \t 0.5819894943548974\n",
      "77 - 72 \t 0.8217467074046466\n",
      "97 - 73 \t 0.6951854630397265\n",
      "97 - 74 \t 0.29418543296279004\n",
      "68 - 75 \t 0.9643788796643794\n",
      "90 - 76 \t 0.7423308965357148\n",
      "69 - 77 \t 0.6770913833011325\n",
      "24 - 78 \t 0.7966305763442753\n",
      "13 - 79 \t 0.7761601486181487\n",
      "10 - 80 \t 0.8494553366187754\n",
      "42 - 81 \t 0.5413147291050968\n",
      "5 - 82 \t 0.8932010225079916\n",
      "71 - 83 \t 0.668810128049804\n",
      "39 - 84 \t 0.7848569853026659\n",
      "87 - 85 \t 0.27758074992717885\n",
      "43 - 86 \t 0.5946168558868508\n",
      "8 - 87 \t 0.2495923564304174\n",
      "0 - 88 \t 0.858748722824925\n",
      "63 - 89 \t 0.7773869686126144\n",
      "29 - 90 \t 0.36644028303268467\n",
      "38 - 91 \t 0.9539108137184765\n",
      "40 - 92 \t 0.9140589260370051\n",
      "4 - 93 \t 0.6792457818883205\n",
      "21 - 94 \t 0.8458335713481061\n",
      "41 - 95 \t 0.8912112589895513\n",
      "73 - 96 \t 0.9087499025885697\n",
      "49 - 97 \t 0.39072249602877873\n",
      "25 - 98 \t 0.6539767038327085\n",
      "80 - 99 \t 0.6463648086084273\n",
      "[0, 21, 34, 2, 88, 100, 88, 50, 59, 63, 86, 44, 58, 39, 8, 7, 12, 55, 65, 48, 9, 86, 14, 50, 44, 86, 62, 63, 36, 44, 16, 64, 67, 75, 61, 86, 22, 11, 50, 62, 88, 26, 9, 86, 4, 42, 86, 35, 78, 9, 75, 13, 48, 42, 36, 2, 87, 47, 1, 9, 59, 21, 5, 98, 86, 57, 1, 21, 43, 82, 27, 53, 78, 98, 98, 69, 91, 70, 25, 14, 11, 43, 6, 72, 40, 88, 44, 9, 1, 64, 30, 39, 41, 5, 22, 42, 74, 50, 26, 81]\n"
     ]
    }
   ],
   "source": [
    "#construction of complete graph and then min spanning tree to choose a set of assets and used prims algo to construct min spanning tree\n",
    "\n",
    "\n",
    "from math import log\n",
    "\n",
    "#historical return vectors (return implies log(c_{i,t}/c_{i,t+1}))\n",
    "historical_returns=[]\n",
    "for i in range(0,no_of_assets):\n",
    "    ro=dataset.iloc[i]\n",
    "    \n",
    "    row=ro[2:22]#here in 1:5 1 is included and 5 is not included \n",
    "    k=[log(y) for y in row]\n",
    "    historical_returns.append(k)\n",
    "\n",
    "#historical_returns[0]\n",
    "\n",
    "#-----------------------------------------\n",
    "delta=[]\n",
    "edge_length=[]\n",
    "for i in range(0,no_of_assets):\n",
    "    delta.append([])\n",
    "    for j in range(0,no_of_assets):\n",
    "        p=[]#h_{i,t}*h_{j,t}\n",
    "        for t in range(0,20):\n",
    "            p.append(historical_returns[i][t]*historical_returns[j][t])\n",
    "        q=[]#h_{i,t}\n",
    "        for t in range(0,20):\n",
    "            q.append(historical_returns[i][t])\n",
    "        o=[]#h_{j,t}\n",
    "        for t in range(0,20):\n",
    "            o.append(historical_returns[j][t])\n",
    "        s=[]#h_{i,t}^2\n",
    "        for t in range(0,20):\n",
    "            s.append(historical_returns[i][t]*historical_returns[i][t])\n",
    "        m=[]#h_{j,t}^2\n",
    "        for t in range(0,20):\n",
    "            m.append(historical_returns[j][t]*historical_returns[j][t])\n",
    "\n",
    "        delta[i].append(((no_of_assets*sum(p))-(sum(q)*sum(o)))/np.sqrt(((no_of_assets*sum(s))-(sum(q)*sum(q)))*((no_of_assets*sum(m))-(sum(o)*sum(o)))))\n",
    "        \n",
    "for i in range(0,no_of_assets):\n",
    "    edge_length.append([])\n",
    "    for j in range(0,no_of_assets):\n",
    "        y=np.sqrt(2*(1-delta[i][j]))\n",
    "        edge_length[i].append(y)\n",
    "#edge_length\n",
    "\n",
    "#--------------------------------------------\n",
    "#prim's algo to calculate adjecency matrix for minimum spanning tree\n",
    "import sys # Library for INT_MAX \n",
    "from itertools import chain\n",
    "from operator import sub\n",
    "imap=map\n",
    "  \n",
    "class Graph(): \n",
    "  \n",
    "    def __init__(self, vertices): \n",
    "        self.V = vertices \n",
    "        self.graph = [[0 for column in range(vertices)]  \n",
    "                    for row in range(vertices)] \n",
    "  \n",
    "    # A utility function to print the constructed MST stored in parent[] \n",
    "    def printMST(self, parent): \n",
    "        print(\"Edge \\tWeight\")\n",
    "        for i in range(1,self.V):\n",
    "            print(parent[i],\"-\",i,\"\\t\",self.graph[i][ parent[i] ])\n",
    "            \n",
    "\n",
    "    \n",
    "    def missing_numbers(self,parent):\n",
    "        parent.sort()\n",
    "        original_list = [x for x in range(parent[0], no_of_assets + 1)]\n",
    "        parent = set(parent)\n",
    "        return (list(parent ^ set(original_list)))\n",
    "    \n",
    "  \n",
    "    # A utility function to find the vertex with  \n",
    "    # minimum distance value, from the set of vertices  \n",
    "    # not yet included in shortest path tree \n",
    "    def minKey(self, key, mstSet): \n",
    "  \n",
    "        # Initilaize min value \n",
    "        min = sys.maxsize \n",
    "  \n",
    "        for v in range(self.V): \n",
    "            if key[v] < min and mstSet[v] == False: \n",
    "                min = key[v] \n",
    "                min_index = v \n",
    "  \n",
    "        return min_index \n",
    "  \n",
    "    # Function to construct and print MST for a graph  \n",
    "    # represented using adjacency matrix representation \n",
    "    def primMST(self): \n",
    "  \n",
    "        #Key values used to pick minimum weight edge in cut \n",
    "        key = [sys.maxsize] * self.V \n",
    "        parent = [None] * self.V # Array to store constructed MST \n",
    "        # Make key 0 so that this vertex is picked as first vertex \n",
    "        key[0] = 0 \n",
    "        mstSet = [False] * self.V \n",
    "  \n",
    "        parent[0] = -1 # First node is always the root of \n",
    "  \n",
    "        for cout in range(self.V): \n",
    "  \n",
    "            # Pick the minimum distance vertex from  \n",
    "            # the set of vertices not yet processed.  \n",
    "            # u is always equal to src in first iteration \n",
    "            u = self.minKey(key, mstSet) \n",
    "  \n",
    "            # Put the minimum distance vertex in  \n",
    "            # the shortest path tree \n",
    "            mstSet[u] = True\n",
    "  \n",
    "            # Update dist value of the adjacent vertices  \n",
    "            # of the picked vertex only if the current  \n",
    "            # distance is greater than new distance and \n",
    "            # the vertex in not in the shotest path tree \n",
    "            for v in range(self.V): \n",
    "                # graph[u][v] is non zero only for adjacent vertices of m \n",
    "                # mstSet[v] is false for vertices not yet included in MST \n",
    "                # Update the key only if graph[u][v] is smaller than key[v] \n",
    "                if self.graph[u][v] > 0 and mstSet[v] == False and key[v] > self.graph[u][v]: \n",
    "                        key[v] = self.graph[u][v] \n",
    "                        parent[v] = u \n",
    "  \n",
    "        self.printMST(parent)\n",
    "        new_list = [x+1 for x in parent]\n",
    "        print(new_list)\n",
    "        return(self.missing_numbers(new_list))\n",
    "        \n",
    "\n",
    "g = Graph(no_of_assets) \n",
    "n = no_of_assets\n",
    "matrix = np.zeros((n,no_of_assets)) # Pre-allocate matrix\n",
    "for i in range(0,n):\n",
    "    matrix[i,:] = edge_length[i]\n",
    "g.graph = matrix\n",
    "  \n",
    "k=g.primMST(); \n",
    "#k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dataset.loc[k,:]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reward of trial t will be revealed at trial t+1\n",
    "#generate reward\n",
    "historical_reward=[]\n",
    "present_reward=[]\n",
    "\n",
    "for t in range(1,21):\n",
    "   # historical_reward.append([])\n",
    "    #m=[]\n",
    "    #for i in range(0,len(k)):\n",
    "    historical_reward.append((4/3)*(1+((1/(np.pi))*(np.arctan(np.log(df.loc[:,'H'+str(t)])))))**2-(4/3))\n",
    "for t in range(1,no_of_trials+1):\n",
    "    present_reward.append((4/3)*(1+((1/(np.pi))*(np.arctan(np.log(df.loc[:,'R'+str(t)])))))**2-(4/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#historical_reward[1]\n",
    "#print(k)\n",
    "#present_reward\n",
    "#historical_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_reward=[]\n",
    "for i in range(0,20):\n",
    "    column_reward.append(historical_reward[i])\n",
    "for i in range(0,no_of_trials):\n",
    "    column_reward.append(present_reward[i])\n",
    "\n",
    "dataset_reward = pd.DataFrame({})\n",
    "\n",
    "dataset_reward['H1']=column_reward[0]\n",
    "for j in range (0,19):\n",
    "    dataset_reward[h[j]]=column_reward[j+1]\n",
    "    \n",
    "for j in range(19,no_of_trials+19):\n",
    "    dataset_reward[r[j-19]]=column_reward[j+1]\n",
    "    \n",
    "#dataset_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical reward vector has different indexes \n",
    "#hence to take average columnwise, we have to construsct another variable 'p'\n",
    "p=[]\n",
    "for i in range(0,20):\n",
    "    p.append(historical_reward[i][k[1]])\n",
    "#p\n",
    "#sum(p)/len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get estimated reward vector at trial t\n",
    "def estimated_reward(t):#get_mean()\n",
    "    asset, trial = no_of_assets, no_of_trials;\n",
    "    r_hat = [] #\\hat{r_{i,t}}\n",
    "    for i in range(0,len(k)):\n",
    "        if(t==1):\n",
    "            p=[]\n",
    "            for j in range(0,20):\n",
    "                p.append(historical_reward[j][k[i]])\n",
    "            r_hat.append(sum(p)/len(p))\n",
    "            #r_hat.append(df.loc[i,\"H1\":\"H20\"].mean()) \n",
    "        else:\n",
    "            q=[]\n",
    "            for j in range(0,20):\n",
    "                q.append(historical_reward[j][k[i]])\n",
    "            for j in range(0,t-1):#trial 2 par R1 tak ka mean chahiye which is present_reward[0]\n",
    "                q.append(present_reward[j][k[i]])\n",
    "            r_hat.append(sum(q)/len(q))\n",
    "            #r_hat.append(df.loc[i,\"H1\":\"R\"+str(t-1)].mean())\n",
    "    return r_hat\n",
    "#print(estimated_reward(1))\n",
    "#estimated_reward(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def estimated_reward_plus(t):\n",
    "    #n=number_of_assets in formula\n",
    "    #vector=np.array([20] * df.shape[0])\n",
    "        \n",
    "    T=[None]*(no_of_assets+1)\n",
    "    for i in range(0,len(k)):\n",
    "        T[k[i]]=20\n",
    "    for j in range(0,t):\n",
    "        for i in range(0,len(k)):\n",
    "            T[k[i]]=T[k[i]]+1\n",
    "\n",
    "    error=[(1/(2*T[i]))*np.log((2*no_of_assets)/(mu)) for i in (k)]\n",
    "    ret=map(sum, zip(estimated_reward(t),error))   \n",
    "    return list(ret)\n",
    "    \n",
    "def estimated_reward_minus(t):\n",
    "    T=[None]*(no_of_assets+1)\n",
    "    for i in range(0,len(k)):\n",
    "        T[k[i]]=20\n",
    "    for j in range(0,t):\n",
    "        for i in range(0,len(k)):\n",
    "            T[k[i]]=T[k[i]]+1\n",
    "\n",
    "    error=[(1/(2*T[i]))*np.log((2*no_of_assets)/(mu)) for i in (k)]\n",
    "    ret=map(operator.sub, estimated_reward(t),error)\n",
    "        \n",
    "    return list(ret)\n",
    "    \n",
    "#print(estimated_reward_plus(1))\n",
    "#print(estimated_reward_minus(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending element to a list\n",
    "#n=get_cost(1)\n",
    "#n.append(1)\n",
    "#n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_cost(1))\n",
    "#print(k)\n",
    "#test code to construct (get_cost_for_k(t))\n",
    "#m=[get_cost(1)[x] for x in k]# here if k[0]=2, then it will give get_cost(1)[2], i.e. 3rd entry, hence not correct\n",
    "#m=[get_cost(2)[x-1] for x in k]\n",
    "#m\n",
    "\n",
    "#get_cost_for_k\n",
    "def get_cost_for_k(t):\n",
    "    m=[get_cost(t)[x-1] for x in k]\n",
    "    return m\n",
    "#get_cost_for_k(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO module docstring\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseOptimizer:\n",
    "    def __init__(self, n_assets, weight_bounds=(0, 1)):\n",
    "        \"\"\"\n",
    "        :param weight_bounds: minimum and maximum weight of an asset, defaults to (0, 1).\n",
    "                              Must be changed to (-1, 1) for portfolios with shorting.\n",
    "        :type weight_bounds: tuple, optional\n",
    "        \"\"\"\n",
    "        self.n_assets = n_assets\n",
    "        self.bounds = self._make_valid_bounds(weight_bounds)\n",
    "        # Optimisation parameters\n",
    "        self.initial_guess = np.array([1 / self.n_assets] * self.n_assets)\n",
    "        self.constraints = [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1}]\n",
    "        # Outputs\n",
    "        self.weights = None\n",
    "\n",
    "    def _make_valid_bounds(self, test_bounds):\n",
    "        \"\"\"\n",
    "        Private method: process input bounds into a form acceptable by scipy.optimize,\n",
    "        and check the validity of said bounds.\n",
    "        :param test_bounds: minimum and maximum weight of an asset\n",
    "        :type test_bounds: tuple\n",
    "        :raises ValueError: if ``test_bounds`` is not a tuple of length two.\n",
    "        :raises ValueError: if the lower bound is too high\n",
    "        :return: a tuple of bounds, e.g ((0, 1), (0, 1), (0, 1) ...)\n",
    "        :rtype: tuple of tuples\n",
    "        \"\"\"\n",
    "        if len(test_bounds) != 2 or not isinstance(test_bounds, tuple):\n",
    "            raise ValueError(\n",
    "                \"test_bounds must be a tuple of (lower bound, upper bound)\"\n",
    "            )\n",
    "        if test_bounds[0] is not None:\n",
    "            if test_bounds[0] * self.n_assets > 1:\n",
    "                raise ValueError(\"Lower bound is too high\")\n",
    "        return (test_bounds,) * self.n_assets\n",
    "\n",
    "    def clean_weights(self, cutoff=1e-4, rounding=5):\n",
    "        \"\"\"\n",
    "        Helper method to clean the raw weights, setting any weights whose absolute\n",
    "        values are below the cutoff to zero, and rounding the rest.\n",
    "        :param cutoff: the lower bound, defaults to 1e-4\n",
    "        :type cutoff: float, optional\n",
    "        :param rounding: number of decimal places to round the weights, defaults to 5.\n",
    "                         Set to None if rounding is not desired.\n",
    "        :type rounding: int, optional\n",
    "        :return: asset weights\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        if not isinstance(rounding, int) or rounding < 1:\n",
    "            raise ValueError(\"rounding must be a positive integer\")\n",
    "        clean_weights = self.weights.copy()\n",
    "        clean_weights[np.abs(clean_weights) < cutoff] = 0\n",
    "        if rounding is not None:\n",
    "            clean_weights = np.round(clean_weights, rounding)\n",
    "        return dict(zip(self.tickers, clean_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The ``objective_functions`` module provides optimisation objectives, including the actual\n",
    "objective functions called by the ``EfficientFrontier`` object's optimisation methods.\n",
    "These methods are primarily designed for internal use during optimisation (via\n",
    "scipy.optimize), and each requires a certain signature (which is why they have not been\n",
    "factored into a class). For obvious reasons, any objective function must accept ``weights``\n",
    "as an argument, and must also have at least one of ``expected_returns`` or ``cov_matrix``.\n",
    "Because scipy.optimize only minimises, any objectives that we want to maximise must be\n",
    "made negative.\n",
    "Currently implemented:\n",
    "- negative mean return\n",
    "- (regularised) negative Sharpe ratio\n",
    "- (regularised) volatility\n",
    "- CVaR (expected shortfall)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def negative_mean_return(weights, expected_returns):\n",
    "    \"\"\"\n",
    "    Calculate the negative mean return of a portfolio\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param expected_returns: expected return of each asset\n",
    "    :type expected_returns: pd.Series\n",
    "    :return: negative mean return\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return -weights.dot(expected_returns)\n",
    "\n",
    "\n",
    "def negative_sharpe(\n",
    "    weights, expected_returns, cov_matrix, gamma=0, risk_free_rate=0.02\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the negative Sharpe ratio of a portfolio\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param expected_returns: expected return of each asset\n",
    "    :type expected_returns: pd.Series\n",
    "    :param cov_matrix: the covariance matrix of asset returns\n",
    "    :type cov_matrix: pd.DataFrame\n",
    "    :param gamma: L2 regularisation parameter, defaults to 0. Increase if you want more\n",
    "                    non-negligible weights\n",
    "    :type gamma: float, optional\n",
    "    :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02\n",
    "    :type risk_free_rate: float, optional\n",
    "    :return: negative Sharpe ratio\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    mu = weights.dot(expected_returns)\n",
    "    sigma = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights.T)))\n",
    "    L2_reg = gamma * (weights ** 2).sum()\n",
    "    return -(mu - risk_free_rate) / sigma + L2_reg\n",
    "\n",
    "\n",
    "def volatility(weights, cov_matrix, gamma=0):\n",
    "    \"\"\"\n",
    "    Calculate the volatility of a portfolio. This is actually a misnomer because\n",
    "    the function returns variance, which is technically the correct objective\n",
    "    function when minimising volatility.\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param cov_matrix: the covariance matrix of asset returns\n",
    "    :type cov_matrix: pd.DataFrame\n",
    "    :param gamma: L2 regularisation parameter, defaults to 0. Increase if you want more\n",
    "                  non-negligible weights\n",
    "    :type gamma: float, optional\n",
    "    :return: portfolio variance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    L2_reg = gamma * (weights ** 2).sum()\n",
    "    portfolio_volatility = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    return portfolio_volatility + L2_reg\n",
    "\n",
    "\n",
    "def negative_cvar(weights, returns,t, s=10000, beta=0.95, random_state=None):\n",
    "    \"\"\"\n",
    "    Calculate the negative CVaR. Though we want the \"min CVaR portfolio\", we\n",
    "    actually need to maximise the expected return of the worst q% cases, thus\n",
    "    we need this value to be negative.\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param returns: asset returns\n",
    "    :type returns: pd.DataFrame or np.ndarray\n",
    "    :param s: number of bootstrap draws, defaults to 10000\n",
    "    :type s: int, optional\n",
    "    :param beta: \"significance level\" (i. 1 - q), defaults to 0.95\n",
    "    :type beta: float, optional\n",
    "    :param random_state: seed for random sampling, defaults to None\n",
    "    :type random_state: int, optional\n",
    "    :return: negative CVaR\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    returns = returns.loc[:,:\"R\"+str(t)]\n",
    "    #weights=x[i][t]/sum(x[i][t])\n",
    "    np.random.seed(seed=random_state)\n",
    "    # Calcualte the returns given the weights\n",
    "    weights_new = weights.reshape((df.shape[0], 1))\n",
    "    portfolio_returns = (weights_new* returns).sum(axis=0)\n",
    "    # Sample from the historical distribution\n",
    "    dist = scipy.stats.gaussian_kde(portfolio_returns)\n",
    "    sample = dist.resample(s)\n",
    "    # Calculate the value at risk\n",
    "    var = portfolio_returns.quantile(1 - beta)\n",
    "    # Mean of all losses worse than the value at risk\n",
    "    return -sample[sample < var].mean()\n",
    "\n",
    "def negative_cvar(weights, returns,t, s=10000, beta=0.95, random_state=None):\n",
    "    \"\"\"\n",
    "    Calculate the negative CVaR. Though we want the \"min CVaR portfolio\", we\n",
    "    actually need to maximise the expected return of the worst q% cases, thus\n",
    "    we need this value to be negative.\n",
    "    :param weights: asset weights of the portfolio\n",
    "    :type weights: np.ndarray\n",
    "    :param returns: asset returns\n",
    "    :type returns: pd.DataFrame or np.ndarray\n",
    "    :param s: number of bootstrap draws, defaults to 10000\n",
    "    :type s: int, optional\n",
    "    :param beta: \"significance level\" (i. 1 - q), defaults to 0.95\n",
    "    :type beta: float, optional\n",
    "    :param random_state: seed for random sampling, defaults to None\n",
    "    :type random_state: int, optional\n",
    "    :return: negative CVaR\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    returns = returns.loc[:,:\"R\"+str(t)]\n",
    "    \n",
    "    #weights=x[i][t]/sum(x[i][t])\n",
    "    np.random.seed(seed=random_state)\n",
    "    # Calcualte the returns given the weights\n",
    "    weights_new = weights.reshape((df.shape[0], 1))\n",
    "    portfolio_returns = (weights_new* returns).sum(axis=0)\n",
    "    # Sample from the historical distribution\n",
    "    dist = scipy.stats.gaussian_kde(portfolio_returns)\n",
    "    sample = dist.resample(s)\n",
    "    # Calculate the value at risk\n",
    "    var = portfolio_returns.quantile(1 - beta)\n",
    "    # Mean of all losses worse than the value at risk\n",
    "    return -sample[sample < var].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The ``value_at_risk`` module allows for optimisation with a (conditional)\n",
    "value-at-risk (CVaR) objective, which requires Monte Carlo simulation.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "#from .base_optimizer import BaseOptimizer\n",
    "#from . import objective_functions\n",
    "import noisyopt\n",
    "\n",
    "\n",
    "class CVAROpt(BaseOptimizer):\n",
    "\n",
    "    \"\"\"\n",
    "    A CVAROpt object (inheriting from BaseOptimizer) provides a method for\n",
    "    optimising the CVaR (a.k.a expected shortfall) of a portfolio.\n",
    "    Instance variables:\n",
    "    - Inputs\n",
    "        - ``tickers``\n",
    "        - ``returns``\n",
    "        - ``bounds``\n",
    "    - Optimisation parameters:\n",
    "        - ``s``: the number of Monte Carlo simulations\n",
    "        - ``beta``: the critical value\n",
    "    - Output: ``weights``\n",
    "    Public methods:\n",
    "    - ``min_cvar()``\n",
    "    - ``normalize_weights()``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, returns, weight_bounds=(0, 1)):\n",
    "        \"\"\"\n",
    "        :param returns: asset historical returns\n",
    "        :type returns: pd.DataFrame\n",
    "        :param weight_bounds: minimum and maximum weight of an asset, defaults to (0, 1).\n",
    "                              Must be changed to (-1, 1) for portfolios with shorting.\n",
    "                              For CVaR opt, this is not a hard boundary.\n",
    "        :type weight_bounds: tuple, optional\n",
    "        :raises TypeError: if ``returns`` is not a dataframe\n",
    "        \"\"\"\n",
    "        if not isinstance(returns, pd.DataFrame):\n",
    "            raise TypeError(\"returns are not a dataframe\")\n",
    "        self.returns = returns\n",
    "        self.tickers = returns.index\n",
    "        super().__init__(returns.shape[0], weight_bounds)  # bounds\n",
    "\n",
    "    def min_cvar(self,t, s=10000, beta=0.95, random_state=None):\n",
    "        \"\"\"\n",
    "        Find the portfolio weights that minimises the CVaR, via\n",
    "        Monte Carlo sampling from the return distribution.\n",
    "        :param s: number of bootstrap draws, defaults to 10000\n",
    "        :type s: int, optional\n",
    "        :param beta: \"significance level\" (i. 1 - q), defaults to 0.95\n",
    "        :type beta: float, optional\n",
    "        :param random_state: seed for random sampling, defaults to None\n",
    "        :type random_state: int, optional\n",
    "        :return: asset weights for the Sharpe-maximising portfolio\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        args = (self.returns,t, s, beta, random_state)\n",
    "        result = noisyopt.minimizeSPSA(\n",
    "            negative_cvar,\n",
    "            args=args,\n",
    "            bounds=self.bounds,\n",
    "            x0=self.initial_guess,\n",
    "            niter=1000,\n",
    "            paired=False,\n",
    "        )\n",
    "        self.weights = self.normalize_weights(result[\"x\"])\n",
    "        return dict(zip(self.tickers, self.weights))\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_weights(raw_weights):\n",
    "        \"\"\"\n",
    "        Make all weights sum to 1\n",
    "        :param raw_weights: input weights which do not sum to 1\n",
    "        :type raw_weights: np.array, pd.Series\n",
    "        :return: normalized weights\n",
    "        :rtype: np.array, pd.Series\n",
    "        \"\"\"\n",
    "        return raw_weights / raw_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.807144856715095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.210368309852154"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cvar if I weight all assets equally \n",
    "returns = dataset_reward.pct_change(axis='columns').dropna(how=\"all\")\n",
    "#returns = returns.loc[:,:\"R\"+str(t)]\n",
    "w = np.array([1 / df.shape[0]] * df.shape[0])\n",
    "w_new = w.reshape((df.shape[0], 1))\n",
    "cvar0 = negative_cvar(w_new, returns,1,s=5000, random_state=0)\n",
    "assert cvar0 > 0\n",
    "cvar1 = negative_cvar(w_new, returns,1, s=5000, beta=0.98, random_state=0)\n",
    "assert cvar1 > 0\n",
    "\n",
    "#Nondeterministic\n",
    "cvar2 = negative_cvar(w_new, returns,1, s=5000, random_state=1)\n",
    "assert not cvar0 == cvar2\n",
    "print(cvar0)\n",
    "cvar2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.244835472150232\n"
     ]
    }
   ],
   "source": [
    "#min cvar \n",
    "vr = CVAROpt(returns)\n",
    "w1 = vr.min_cvar(1,s=5000, random_state=0)\n",
    "assert isinstance(w1, dict)\n",
    "assert set(w1.keys()) == set(dataset_reward.index)\n",
    "assert set(w1.keys()) == set(vr.tickers)\n",
    "np.testing.assert_almost_equal(vr.weights.sum(), 1)\n",
    "\n",
    "#w1\n",
    "w1=np.array(list(dict.values(w1)))\n",
    "#w1\n",
    "w1_new = w1.reshape((df.shape[0], 1))\n",
    "cvar_min = negative_cvar(w1_new, returns, 1,s=5000, random_state=0)\n",
    "print(cvar_min)\n",
    "#w1_new\n",
    "#w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get x_{i,1}'s for all i \\in k \n",
    "def get_start_point(t, weight):\n",
    "    x=[Cost_Bound/get_cost_for_k(t)[i] for i in range(0,len(k))  ]\n",
    "    s=sum(x)\n",
    "    #l = [x * 2 for x in l]\n",
    "    x=[l*s for l in weight]\n",
    "    return list(x)\n",
    "    #x=np.array([Cost_Bound / get_cost_for_k(t)] )\n",
    "#get_start_point(1,w1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to convert it into array to simple type to be accepted in LP programe \n",
    "#o=get_start_point(1,w1)\n",
    "#o.append(0)\n",
    "#o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Karmarskar algorithm to solve system of linear equation and get x_{i,1} for 1st 2 equations in optimization problem \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LPSolution(object):\n",
    "    def __init__(self):\n",
    "        self.iterations = None\n",
    "        self.tolerance = None\n",
    "        self.intermediates = []\n",
    "        self.solution = []\n",
    "        self.solution_string = None\n",
    "\n",
    "    def __str__(self):\n",
    "        self.solution_string =str(self.solution)\n",
    "        #self.solution_string += '\\n\\tTolerance: ' + str(self.tolerance)\n",
    "        #self.solution_string += '\\n\\tIterations: ' + str(self.iterations)\n",
    "        return self.solution_string\n",
    "\n",
    "\n",
    "class LinearProgram(object):\n",
    "    \"\"\"A class that implements Karmarkar's Algorithm for the solution of\n",
    "    Linear Programs in standard form.\"\"\"\n",
    "    def __init__(self, A, b, c):\n",
    "        \"\"\"Constructs an n-variable m-constraint Linear Program.\n",
    "\n",
    "        A -- An n x m numpy matrix of constraint coefficients\n",
    "        b -- A 1 x m numpy row vector of constraint RHS values\n",
    "        c -- A 1 x n numpy row vector of objective function coefficients\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.n, self.m = self.A.shape\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.solution = []\n",
    "\n",
    "    def karmarkar(self, start_point):\n",
    "        \"\"\"Runs one iteration of Karmarkar's Algorithm.\n",
    "\n",
    "        start_point -- A 1 x n numpy row vector of decision variable values\n",
    "        \"\"\"\n",
    "        D = np.diagflat(start_point)\n",
    "        c_tilde = np.matmul(self.c, D)\n",
    "        A_tilde = np.matmul(self.A, D)\n",
    "        A_tildeT = A_tilde.transpose()\n",
    "        AAT_inverse = np.linalg.inv(np.matmul(A_tilde, A_tildeT))\n",
    "        # matrix multiplication is associative\n",
    "        P = np.identity(self.m) - np.matmul(np.matmul(A_tildeT, AAT_inverse), A_tilde)\n",
    "        cp_tilde = np.matmul(c_tilde, P)\n",
    "        k = -0.5 / np.amin(cp_tilde)\n",
    "        x_tilde_new = np.ones((1, self.m), order='F') + k * cp_tilde\n",
    "        return np.matmul(x_tilde_new, D)\n",
    "\n",
    "    def solve(self, start_point, tolerance=1e-5, max_iterations=50, verbose=False):\n",
    "        \"\"\"Uses Karmarkar's Algorithm to solve a Linear Program.\n",
    "\n",
    "        start_point     -- A starting point for Karmarkar's Algorithm. Must be a row vector.\n",
    "        tolerance       -- The stopping tolerance of Karmarkar's Algorithm.\n",
    "        max_iterations  -- The maximum number of iterations to run Karmarkar's Algorithm.\n",
    "        verbose         -- List all intermediate values.\n",
    "        \"\"\"\n",
    "        x = start_point\n",
    "        solution = LPSolution()\n",
    "        for i in range(max_iterations):\n",
    "            x_new = self.karmarkar(x)\n",
    "            if verbose:\n",
    "                print(x_new)\n",
    "\n",
    "            dist = np.linalg.norm(x - x_new)\n",
    "            x = x_new\n",
    "            solution.intermediates.append(x)\n",
    "            if dist < tolerance:\n",
    "                break\n",
    "\n",
    "        solution.solution = x\n",
    "        solution.iterations = i\n",
    "        solution.tolerance = dist\n",
    "        self.solution = solution\n",
    "\n",
    "        return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#k=get_cost(1)\n",
    "#k.append(1)\n",
    "#!/usr/bin/python3\n",
    "import numpy as np\n",
    "#from linear_program import LinearProgram, LPSolution\n",
    "\n",
    "\n",
    "def generate_tikz_plot(solution):\n",
    "    \"\"\"Generates a 3D Tikz LaTeX coordinate strings for the intermediate solutions.\"\"\"\n",
    "    for i, soln in enumerate(solution.intermediates):\n",
    "        coordinate = r'\\coordinate (xnew{}) at '.format(i)\n",
    "        coordinate += r'({}, {}, {});'.format(*[coord for coord in soln.flat])\n",
    "        print(coordinate)\n",
    "\n",
    "    draw = r'\\draw[red] (x) node[circle, fill, inner sep=1pt] '\n",
    "    for i in range(len(solution.intermediates)):\n",
    "        draw += r'-- (xnew{}) node[circle, fill, inner sep=1pt] '.format(i)\n",
    "    draw += r';'\n",
    "    print(draw)\n",
    "\n",
    "\n",
    "def main():\n",
    "    n=get_cost_for_k(1)\n",
    "    n.append(1)\n",
    "    \n",
    "    m=estimated_reward(1)\n",
    "    m.append(0)\n",
    "    \n",
    "    o=get_start_point(1,w1)\n",
    "    o.append(0)\n",
    "    o\n",
    "    \n",
    "    #k.append(1)\n",
    "    #A = np.matrix([get_cost(t), ])\n",
    "    A = np.matrix([n, ])\n",
    "    b = np.array([Cost_Bound, ])\n",
    "    #c = np.array([1, 2, 0])\n",
    "    c = np.array(m)\n",
    "\n",
    "    LP = LinearProgram(A, b, c)\n",
    "    LP.solve(start_point=np.array(o))\n",
    "    return (LP.solution)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=main()\n",
    "#print(y)\n",
    "#str(y)\n",
    "def Convert(string): \n",
    "    li = list(string.split( )) \n",
    "    return li \n",
    "y=Convert(str(main()))\n",
    "x_k_1 = list(filter(None,y )) # fastest\n",
    "#print(y)\n",
    "#print(x_k_1)\n",
    "\n",
    "#removing \"\\n\" part from the list\n",
    "x_k_1=list(map(str.strip,x_k_1))\n",
    "#print(x_k_1)\n",
    "\n",
    "#removing last element from the list\n",
    "x_k_1=x_k_1[:-1]\n",
    "#x_k_1\n",
    "\n",
    "#removing unneccesory elements from 1st element of x_k_1\n",
    "#print(x_k_1[0])\n",
    "type(x_k_1)\n",
    "#sum(float(i) for i in x_k_1)\n",
    "\n",
    "#print(x_k_1[0])\n",
    "x_k_1[0]=x_k_1[0][2:]\n",
    "#x_k_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting every element of x_k_1 which was initially string type to float type\n",
    "x_k_1=[float(x) for x in x_k_1]\n",
    "#x_k_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.02272727, 0.02272727, 0.02272727, 0.02272727])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weight_from_securities(x):\n",
    "    weight=[x[i]/sum(x) for i in range(0,len(k))]\n",
    "    return weight\n",
    "weight_from_securities=get_weight_from_securities(x_k_1)\n",
    "weight_from_securities=np.array(w)\n",
    "weight_from_securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.807144856715095"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvar = negative_cvar( weight_from_securities, returns,1,s=5000, random_state=0)\n",
    "assert cvar > 0\n",
    "cvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant(f,a,b,N):\n",
    "    '''Approximate solution of f(x)=0 on interval [a,b] by the secant method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        The function for which we are trying to approximate a solution f(x)=0.\n",
    "    a,b : numbers\n",
    "        The interval in which to search for a solution. The function returns\n",
    "        None if f(a)*f(b) >= 0 since a solution is not guaranteed.\n",
    "    N : (positive) integer\n",
    "        The number of iterations to implement.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    m_N : number\n",
    "        The x intercept of the secant line on the the Nth interval\n",
    "            m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n))\n",
    "        The initial interval [a_0,b_0] is given by [a,b]. If f(m_n) == 0\n",
    "        for some intercept m_n then the function returns this solution.\n",
    "        If all signs of values f(a_n), f(b_n) and f(m_n) are the same at any\n",
    "        iterations, the secant method fails and return None.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> f = lambda x: x**2 - x - 1\n",
    "    >>> secant(f,1,2,5)\n",
    "    1.6180257510729614\n",
    "    '''\n",
    "    if f(a)*f(b) >= 0:\n",
    "        print(\"Secant method fails.\")\n",
    "        return None\n",
    "    a_n = a\n",
    "    b_n = b\n",
    "    for n in range(1,N+1):\n",
    "        m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n))\n",
    "        f_m_n = f(m_n)\n",
    "        if f(a_n)*f_m_n < 0:\n",
    "            a_n = a_n\n",
    "            b_n = m_n\n",
    "        elif f(b_n)*f_m_n < 0:\n",
    "            a_n = m_n\n",
    "            b_n = b_n\n",
    "        elif f_m_n == 0:\n",
    "            print(\"Found exact solution.\")\n",
    "            return m_n\n",
    "        else:\n",
    "            print(\"Secant method fails.\")\n",
    "            return None\n",
    "    return a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secant method fails.\n"
     ]
    }
   ],
   "source": [
    "def f(o):\n",
    "    return (negative_cvar(o, returns,1,s=5000, random_state=0)-theta*cvar_min)\n",
    "\n",
    "#f=(negative_cvar( w, returns,1,s=5000, random_state=0)-theta*cvar_min)\n",
    "random_guess_for_weight=np.array([1 / df.shape[0]] * df.shape[0])\n",
    "secant(f, weight_from_securities,random_guess_for_weight,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n"
     ]
    }
   ],
   "source": [
    "if (cvar<=theta*cvar_min):\n",
    "    print(\"yay\")\n",
    "else: \n",
    "    #random_guess_for_weight=np.array([1 / df.shape[0]] * df.shape[0])\n",
    "    secant(f, weight_from_securities,w1_new,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
